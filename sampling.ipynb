{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "import childespy\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_BINS = 5\n",
    "TOTAL_SAMPLES = 1000\n",
    "MAX_POS_SAMPLES = 250\n",
    "\n",
    "# need collection, language, corpus, and role if token_csv_name is none\n",
    "COLLECTION = None\n",
    "LANGUAGE = None\n",
    "CORPUS = 'Providence'\n",
    "ROLE = None\n",
    "\n",
    "UTTERANCE_CSV_NAME = None \n",
    "TOKEN_CSV_NAME = None\n",
    "\n",
    "FULL_SAMPLED_TOKENS_CSV_NAME = 'sampled_full.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (TOKEN_CSV_NAME is not None and path.exists(TOKEN_CSV_NAME)):\n",
    "    all_tokens = pd.read_csv(TOKEN_CSV_NAME, keep_default_na = False, index_col=0)\n",
    "else:\n",
    "    all_tokens = childespy.get_tokens(collection=COLLECTION, language=LANGUAGE, corpus=CORPUS, role=ROLE, token=\"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gloss</th>\n",
       "      <th>language</th>\n",
       "      <th>token_order</th>\n",
       "      <th>prefix</th>\n",
       "      <th>part_of_speech</th>\n",
       "      <th>stem</th>\n",
       "      <th>actual_phonology</th>\n",
       "      <th>model_phonology</th>\n",
       "      <th>suffix</th>\n",
       "      <th>...</th>\n",
       "      <th>target_child_name</th>\n",
       "      <th>target_child_age</th>\n",
       "      <th>target_child_sex</th>\n",
       "      <th>collection_name</th>\n",
       "      <th>collection_id</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>target_child_id</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>utterance_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61164901</td>\n",
       "      <td>where</td>\n",
       "      <td>eng</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>pro</td>\n",
       "      <td>where</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Alex</td>\n",
       "      <td>16.887410</td>\n",
       "      <td>male</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>21</td>\n",
       "      <td>328</td>\n",
       "      <td>22708</td>\n",
       "      <td>22704</td>\n",
       "      <td>42204</td>\n",
       "      <td>16759250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61164902</td>\n",
       "      <td>do</td>\n",
       "      <td>eng</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>mod</td>\n",
       "      <td>do</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Alex</td>\n",
       "      <td>16.887410</td>\n",
       "      <td>male</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>21</td>\n",
       "      <td>328</td>\n",
       "      <td>22708</td>\n",
       "      <td>22704</td>\n",
       "      <td>42204</td>\n",
       "      <td>16759250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61164903</td>\n",
       "      <td>you</td>\n",
       "      <td>eng</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>pro</td>\n",
       "      <td>you</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Alex</td>\n",
       "      <td>16.887410</td>\n",
       "      <td>male</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>21</td>\n",
       "      <td>328</td>\n",
       "      <td>22708</td>\n",
       "      <td>22704</td>\n",
       "      <td>42204</td>\n",
       "      <td>16759250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61164904</td>\n",
       "      <td>want</td>\n",
       "      <td>eng</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>v</td>\n",
       "      <td>want</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Alex</td>\n",
       "      <td>16.887410</td>\n",
       "      <td>male</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>21</td>\n",
       "      <td>328</td>\n",
       "      <td>22708</td>\n",
       "      <td>22704</td>\n",
       "      <td>42204</td>\n",
       "      <td>16759250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>61164905</td>\n",
       "      <td>me</td>\n",
       "      <td>eng</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>pro</td>\n",
       "      <td>me</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Alex</td>\n",
       "      <td>16.887410</td>\n",
       "      <td>male</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>21</td>\n",
       "      <td>328</td>\n",
       "      <td>22708</td>\n",
       "      <td>22704</td>\n",
       "      <td>42204</td>\n",
       "      <td>16759250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814599</th>\n",
       "      <td>63103187</td>\n",
       "      <td>lick</td>\n",
       "      <td>eng</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>v</td>\n",
       "      <td>lick</td>\n",
       "      <td>liʔ</td>\n",
       "      <td>lɪk</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>William</td>\n",
       "      <td>39.822173</td>\n",
       "      <td>male</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>21</td>\n",
       "      <td>328</td>\n",
       "      <td>22764</td>\n",
       "      <td>22764</td>\n",
       "      <td>42569</td>\n",
       "      <td>17280964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814600</th>\n",
       "      <td>63103188</td>\n",
       "      <td>hippo</td>\n",
       "      <td>eng</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>n</td>\n",
       "      <td>hippo</td>\n",
       "      <td>ɪ</td>\n",
       "      <td>hɪ</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>William</td>\n",
       "      <td>39.822173</td>\n",
       "      <td>male</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>21</td>\n",
       "      <td>328</td>\n",
       "      <td>22764</td>\n",
       "      <td>22764</td>\n",
       "      <td>42569</td>\n",
       "      <td>17280964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814601</th>\n",
       "      <td>63103189</td>\n",
       "      <td>hippo</td>\n",
       "      <td>eng</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>n</td>\n",
       "      <td>hippo</td>\n",
       "      <td>hɪpo</td>\n",
       "      <td>hɪpoʊ</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>William</td>\n",
       "      <td>39.822173</td>\n",
       "      <td>male</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>21</td>\n",
       "      <td>328</td>\n",
       "      <td>22764</td>\n",
       "      <td>22764</td>\n",
       "      <td>42569</td>\n",
       "      <td>17280992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814604</th>\n",
       "      <td>63103192</td>\n",
       "      <td>la</td>\n",
       "      <td>eng</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>co</td>\n",
       "      <td>la</td>\n",
       "      <td>lɑ</td>\n",
       "      <td>lɑː</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>William</td>\n",
       "      <td>39.822173</td>\n",
       "      <td>male</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>21</td>\n",
       "      <td>328</td>\n",
       "      <td>22764</td>\n",
       "      <td>22764</td>\n",
       "      <td>42569</td>\n",
       "      <td>17281030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814605</th>\n",
       "      <td>63103193</td>\n",
       "      <td>la</td>\n",
       "      <td>eng</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>co</td>\n",
       "      <td>la</td>\n",
       "      <td>lɑ</td>\n",
       "      <td>lɑː</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>William</td>\n",
       "      <td>39.822173</td>\n",
       "      <td>male</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>21</td>\n",
       "      <td>328</td>\n",
       "      <td>22764</td>\n",
       "      <td>22764</td>\n",
       "      <td>42569</td>\n",
       "      <td>17281030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1645885 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  gloss language  token_order prefix part_of_speech   stem  \\\n",
       "1        61164901  where      eng            1                   pro  where   \n",
       "2        61164902     do      eng            2                   mod     do   \n",
       "3        61164903    you      eng            3                   pro    you   \n",
       "4        61164904   want      eng            4                     v   want   \n",
       "5        61164905     me      eng            5                   pro     me   \n",
       "...           ...    ...      ...          ...    ...            ...    ...   \n",
       "1814599  63103187   lick      eng            3                     v   lick   \n",
       "1814600  63103188  hippo      eng            4                     n  hippo   \n",
       "1814601  63103189  hippo      eng            1                     n  hippo   \n",
       "1814604  63103192     la      eng            2                    co     la   \n",
       "1814605  63103193     la      eng            3                    co     la   \n",
       "\n",
       "        actual_phonology model_phonology suffix  ...  target_child_name  \\\n",
       "1                                                ...               Alex   \n",
       "2                                                ...               Alex   \n",
       "3                                                ...               Alex   \n",
       "4                                                ...               Alex   \n",
       "5                                                ...               Alex   \n",
       "...                  ...             ...    ...  ...                ...   \n",
       "1814599              liʔ             lɪk         ...            William   \n",
       "1814600                ɪ              hɪ         ...            William   \n",
       "1814601             hɪpo           hɪpoʊ         ...            William   \n",
       "1814604               lɑ             lɑː         ...            William   \n",
       "1814605               lɑ             lɑː         ...            William   \n",
       "\n",
       "        target_child_age target_child_sex collection_name collection_id  \\\n",
       "1              16.887410             male          Eng-NA            21   \n",
       "2              16.887410             male          Eng-NA            21   \n",
       "3              16.887410             male          Eng-NA            21   \n",
       "4              16.887410             male          Eng-NA            21   \n",
       "5              16.887410             male          Eng-NA            21   \n",
       "...                  ...              ...             ...           ...   \n",
       "1814599        39.822173             male          Eng-NA            21   \n",
       "1814600        39.822173             male          Eng-NA            21   \n",
       "1814601        39.822173             male          Eng-NA            21   \n",
       "1814604        39.822173             male          Eng-NA            21   \n",
       "1814605        39.822173             male          Eng-NA            21   \n",
       "\n",
       "        corpus_id speaker_id target_child_id transcript_id  utterance_id  \n",
       "1             328      22708           22704         42204      16759250  \n",
       "2             328      22708           22704         42204      16759250  \n",
       "3             328      22708           22704         42204      16759250  \n",
       "4             328      22708           22704         42204      16759250  \n",
       "5             328      22708           22704         42204      16759250  \n",
       "...           ...        ...             ...           ...           ...  \n",
       "1814599       328      22764           22764         42569      17280964  \n",
       "1814600       328      22764           22764         42569      17280964  \n",
       "1814601       328      22764           22764         42569      17280992  \n",
       "1814604       328      22764           22764         42569      17281030  \n",
       "1814605       328      22764           22764         42569      17281030  \n",
       "\n",
       "[1645885 rows x 28 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_copy = all_tokens.copy()\n",
    "token_copy = token_copy[token_copy['part_of_speech'].astype(bool)] # omit the empty POS\n",
    "token_copy = token_copy[token_copy['part_of_speech'].str.find(\" \") == -1] # omit multiple-POS entries\n",
    "token_copy = token_copy[~token_copy['gloss'].str.contains('xxx')]\n",
    "token_copy = token_copy[~token_copy['gloss'].str.contains('yyy')]\n",
    "\n",
    "def simplify_pos(pos):\n",
    "    return pos[:pos.find(\":\")] if (pos.find(\":\") != -1 and pos.find(\" \") == -1) else pos\n",
    "\n",
    "def contraction_pos(part_of_speech, clitic, suffix):\n",
    "    '''\n",
    "    this function is very english-centric and childes-centric\n",
    "    could incorporate another model, e.g. spacy, to find contractions\n",
    "    '''\n",
    "    if suffix == \"dn POSS\" or suffix == \"dn AGT POSS\":\n",
    "        return part_of_speech + \"+poss\"\n",
    "    if clitic == \"\":\n",
    "        return part_of_speech\n",
    "    else:\n",
    "        return part_of_speech + \"+\" + clitic.split()[0]\n",
    "\n",
    "simplified_pos_tokens = token_copy.copy()\n",
    "simplified_pos_tokens['part_of_speech'] = token_copy['part_of_speech'].map(simplify_pos)\n",
    "simplified_pos_tokens['part_of_speech'] = simplified_pos_tokens.apply(lambda x: contraction_pos(x['part_of_speech'], x['clitic'], x['suffix']), axis=1)\n",
    "simplified_pos_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id        gloss\n",
      "0    61606126        kayak\n",
      "1    62654815  Nasturtiums\n",
      "2    62006551        curls\n",
      "3    61949202        toads\n",
      "4    61754789         Palm\n",
      "..        ...          ...\n",
      "245  62547206        gonna\n",
      "246  62978642        who's\n",
      "247  61208021         it's\n",
      "248  62224254       that's\n",
      "249  61594043       that's\n",
      "\n",
      "[2347 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "all_samples = pd.DataFrame()\n",
    "\n",
    "def sample_from(pos_df, all_samples):\n",
    "    # aggregate by type to count type frequency within POS\n",
    "    types = pos_df.groupby(['gloss']).id.agg(np.size).reset_index()\n",
    "    pos_df_with_frequency = pos_df.merge(types, on=['gloss'], suffixes=(None, \"_frequency\"))\n",
    "    pos_df_with_frequency.rename(columns={'id_frequency': 'frequency'}, inplace=True)\n",
    "    pos_df_with_frequency['log_frequency'] = np.nan\n",
    "    pos_df_with_frequency['log_frequency'] = np.log(pos_df_with_frequency['frequency'])\n",
    "\n",
    "    # assign frequency bin to each token\n",
    "    token_bins = pd.cut(pos_df_with_frequency['log_frequency'], NUM_BINS, labels=list(range(NUM_BINS)))\n",
    "    pos_df_with_bins = pos_df_with_frequency.join(token_bins, rsuffix=\"_bin\")\n",
    "\n",
    "    samples_per_bin = int(MAX_POS_SAMPLES/NUM_BINS)\n",
    "    logfreq_sampled_tokens = pos_df_with_bins.groupby('log_frequency_bin').apply(lambda x: x.sample(n=samples_per_bin, replace=True) if len(x)>0 else x).reset_index(drop=True)\n",
    "    logfreq_sampled_tokens.drop_duplicates(keep='first', inplace=True)\n",
    "    all_samples = pd.concat([all_samples, logfreq_sampled_tokens])\n",
    "    return all_samples\n",
    "\n",
    "pos_groupby = simplified_pos_tokens.groupby(['part_of_speech'])\n",
    "iterator = [\"n\", \"v\", \"adj\", \"mod\", \"adv\", \"part\", \"prep\", \"pro\", \"det\"]\n",
    "for name in iterator:\n",
    "    pos_df = pos_groupby.get_group(name) # dataframe with only the tokens of this part of speech\n",
    "    all_samples = sample_from(pos_df, all_samples)\n",
    "\n",
    "contraction_df = simplified_pos_tokens[simplified_pos_tokens['part_of_speech'].str.contains(\"\\+\")]\n",
    "all_samples = sample_from(contraction_df, all_samples)\n",
    "\n",
    "print(all_samples[[\"id\", \"gloss\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gloss</th>\n",
       "      <th>language</th>\n",
       "      <th>token_order</th>\n",
       "      <th>prefix</th>\n",
       "      <th>part_of_speech</th>\n",
       "      <th>stem</th>\n",
       "      <th>actual_phonology</th>\n",
       "      <th>model_phonology</th>\n",
       "      <th>suffix</th>\n",
       "      <th>...</th>\n",
       "      <th>collection_name</th>\n",
       "      <th>collection_id</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>target_child_id</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>frequency</th>\n",
       "      <th>log_frequency</th>\n",
       "      <th>log_frequency_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62438075</td>\n",
       "      <td>this</td>\n",
       "      <td>eng</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>pro</td>\n",
       "      <td>this</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>21</td>\n",
       "      <td>328</td>\n",
       "      <td>22744</td>\n",
       "      <td>22743</td>\n",
       "      <td>42448</td>\n",
       "      <td>17084600</td>\n",
       "      <td>10570</td>\n",
       "      <td>9.265775</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61402650</td>\n",
       "      <td>need</td>\n",
       "      <td>eng</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>v</td>\n",
       "      <td>need</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>21</td>\n",
       "      <td>328</td>\n",
       "      <td>22707</td>\n",
       "      <td>22704</td>\n",
       "      <td>42252</td>\n",
       "      <td>16839687</td>\n",
       "      <td>2591</td>\n",
       "      <td>7.859799</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62051390</td>\n",
       "      <td>anything</td>\n",
       "      <td>eng</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>pro</td>\n",
       "      <td>anything</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>21</td>\n",
       "      <td>328</td>\n",
       "      <td>22729</td>\n",
       "      <td>22728</td>\n",
       "      <td>42378</td>\n",
       "      <td>16986849</td>\n",
       "      <td>407</td>\n",
       "      <td>6.008813</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61453077</td>\n",
       "      <td>merrily</td>\n",
       "      <td>eng</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>adv</td>\n",
       "      <td>merry</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>dadj LY</td>\n",
       "      <td>...</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>21</td>\n",
       "      <td>328</td>\n",
       "      <td>22721</td>\n",
       "      <td>22720</td>\n",
       "      <td>42274</td>\n",
       "      <td>16851507</td>\n",
       "      <td>19</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61679240</td>\n",
       "      <td>stretching</td>\n",
       "      <td>eng</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>part</td>\n",
       "      <td>stretch</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>PRESP</td>\n",
       "      <td>...</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>21</td>\n",
       "      <td>328</td>\n",
       "      <td>22721</td>\n",
       "      <td>22720</td>\n",
       "      <td>42294</td>\n",
       "      <td>16923698</td>\n",
       "      <td>2</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>62816244</td>\n",
       "      <td>largest</td>\n",
       "      <td>eng</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>adj</td>\n",
       "      <td>large</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SP</td>\n",
       "      <td>...</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>21</td>\n",
       "      <td>328</td>\n",
       "      <td>22756</td>\n",
       "      <td>22755</td>\n",
       "      <td>42518</td>\n",
       "      <td>17177704</td>\n",
       "      <td>18</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>61971711</td>\n",
       "      <td>picture's</td>\n",
       "      <td>eng</td>\n",
       "      <td>17</td>\n",
       "      <td></td>\n",
       "      <td>n+cop</td>\n",
       "      <td>picture</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>21</td>\n",
       "      <td>328</td>\n",
       "      <td>22729</td>\n",
       "      <td>22728</td>\n",
       "      <td>42372</td>\n",
       "      <td>16979363</td>\n",
       "      <td>3</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>61474947</td>\n",
       "      <td>onto</td>\n",
       "      <td>eng</td>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td>prep</td>\n",
       "      <td>onto</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>21</td>\n",
       "      <td>328</td>\n",
       "      <td>22721</td>\n",
       "      <td>22720</td>\n",
       "      <td>42286</td>\n",
       "      <td>16859093</td>\n",
       "      <td>111</td>\n",
       "      <td>4.709530</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>62551990</td>\n",
       "      <td>dumping</td>\n",
       "      <td>eng</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>part</td>\n",
       "      <td>dump</td>\n",
       "      <td>dʌmpiŋ</td>\n",
       "      <td>dʌmpɪŋ</td>\n",
       "      <td>PRESP</td>\n",
       "      <td>...</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>21</td>\n",
       "      <td>328</td>\n",
       "      <td>22743</td>\n",
       "      <td>22743</td>\n",
       "      <td>42433</td>\n",
       "      <td>17094010</td>\n",
       "      <td>17</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>62904807</td>\n",
       "      <td>mashed</td>\n",
       "      <td>eng</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>part</td>\n",
       "      <td>mash</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>PASTP</td>\n",
       "      <td>...</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>21</td>\n",
       "      <td>328</td>\n",
       "      <td>22766</td>\n",
       "      <td>22764</td>\n",
       "      <td>42548</td>\n",
       "      <td>17198054</td>\n",
       "      <td>6</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id       gloss language  token_order prefix part_of_speech  \\\n",
       "0    62438075        this      eng            1                   pro   \n",
       "1    61402650        need      eng            3                     v   \n",
       "2    62051390    anything      eng            4                   pro   \n",
       "3    61453077     merrily      eng            4                   adv   \n",
       "4    61679240  stretching      eng            3                  part   \n",
       "..        ...         ...      ...          ...    ...            ...   \n",
       "995  62816244     largest      eng            4                   adj   \n",
       "996  61971711   picture's      eng           17                 n+cop   \n",
       "997  61474947        onto      eng            9                  prep   \n",
       "998  62551990     dumping      eng            2                  part   \n",
       "999  62904807      mashed      eng            3                  part   \n",
       "\n",
       "         stem actual_phonology model_phonology   suffix  ...  collection_name  \\\n",
       "0        this                                            ...           Eng-NA   \n",
       "1        need                                            ...           Eng-NA   \n",
       "2    anything                                            ...           Eng-NA   \n",
       "3       merry                                   dadj LY  ...           Eng-NA   \n",
       "4     stretch                                     PRESP  ...           Eng-NA   \n",
       "..        ...              ...             ...      ...  ...              ...   \n",
       "995     large                                        SP  ...           Eng-NA   \n",
       "996   picture                                            ...           Eng-NA   \n",
       "997      onto                                            ...           Eng-NA   \n",
       "998      dump           dʌmpiŋ          dʌmpɪŋ    PRESP  ...           Eng-NA   \n",
       "999      mash                                     PASTP  ...           Eng-NA   \n",
       "\n",
       "    collection_id corpus_id speaker_id target_child_id transcript_id  \\\n",
       "0              21       328      22744           22743         42448   \n",
       "1              21       328      22707           22704         42252   \n",
       "2              21       328      22729           22728         42378   \n",
       "3              21       328      22721           22720         42274   \n",
       "4              21       328      22721           22720         42294   \n",
       "..            ...       ...        ...             ...           ...   \n",
       "995            21       328      22756           22755         42518   \n",
       "996            21       328      22729           22728         42372   \n",
       "997            21       328      22721           22720         42286   \n",
       "998            21       328      22743           22743         42433   \n",
       "999            21       328      22766           22764         42548   \n",
       "\n",
       "    utterance_id frequency log_frequency  log_frequency_bin  \n",
       "0       17084600     10570      9.265775                  4  \n",
       "1       16839687      2591      7.859799                  4  \n",
       "2       16986849       407      6.008813                  2  \n",
       "3       16851507        19      2.944439                  1  \n",
       "4       16923698         2      0.693147                  0  \n",
       "..           ...       ...           ...                ...  \n",
       "995     17177704        18      2.890372                  1  \n",
       "996     16979363         3      1.098612                  0  \n",
       "997     16859093       111      4.709530                  2  \n",
       "998     17094010        17      2.833213                  1  \n",
       "999     17198054         6      1.791759                  1  \n",
       "\n",
       "[1000 rows x 31 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thousand_samples = all_samples.sample(n=TOTAL_SAMPLES).reset_index(drop=True)\n",
    "thousand_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (UTTERANCE_CSV_NAME is not None and path.exists(UTTERANCE_CSV_NAME)):\n",
    "    utterances = pd.read_csv(UTTERANCE_CSV_NAME, keep_default_na=False)\n",
    "else:\n",
    "    utterances = childespy.get_utterances(corpus=CORPUS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>gloss</th>\n",
       "      <th>language</th>\n",
       "      <th>token_order</th>\n",
       "      <th>prefix</th>\n",
       "      <th>stem</th>\n",
       "      <th>actual_phonology</th>\n",
       "      <th>model_phonology</th>\n",
       "      <th>suffix</th>\n",
       "      <th>num_morphemes</th>\n",
       "      <th>...</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>target_child_id</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>frequency</th>\n",
       "      <th>log_frequency</th>\n",
       "      <th>log_frequency_bin</th>\n",
       "      <th>utterance_gloss</th>\n",
       "      <th>part_of_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62438075</td>\n",
       "      <td>this</td>\n",
       "      <td>eng</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>this</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>328</td>\n",
       "      <td>22744</td>\n",
       "      <td>22743</td>\n",
       "      <td>42448</td>\n",
       "      <td>17084600</td>\n",
       "      <td>10570</td>\n",
       "      <td>9.265775</td>\n",
       "      <td>4</td>\n",
       "      <td>this one looks like she's driving a</td>\n",
       "      <td>pro:dem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61402650</td>\n",
       "      <td>need</td>\n",
       "      <td>eng</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>need</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>328</td>\n",
       "      <td>22707</td>\n",
       "      <td>22704</td>\n",
       "      <td>42252</td>\n",
       "      <td>16839687</td>\n",
       "      <td>2591</td>\n",
       "      <td>7.859799</td>\n",
       "      <td>4</td>\n",
       "      <td>now I need</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62051390</td>\n",
       "      <td>anything</td>\n",
       "      <td>eng</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>anything</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>328</td>\n",
       "      <td>22729</td>\n",
       "      <td>22728</td>\n",
       "      <td>42378</td>\n",
       "      <td>16986849</td>\n",
       "      <td>407</td>\n",
       "      <td>6.008813</td>\n",
       "      <td>2</td>\n",
       "      <td>did we see anything else when we were there</td>\n",
       "      <td>pro:indef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61453077</td>\n",
       "      <td>merrily</td>\n",
       "      <td>eng</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>merry</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>dadj LY</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>328</td>\n",
       "      <td>22721</td>\n",
       "      <td>22720</td>\n",
       "      <td>42274</td>\n",
       "      <td>16851507</td>\n",
       "      <td>19</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>1</td>\n",
       "      <td>merrily merrily merrily merrily</td>\n",
       "      <td>adv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61453075</td>\n",
       "      <td>merrily</td>\n",
       "      <td>eng</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>merry</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>dadj LY</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>328</td>\n",
       "      <td>22721</td>\n",
       "      <td>22720</td>\n",
       "      <td>42274</td>\n",
       "      <td>16851507</td>\n",
       "      <td>19</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>1</td>\n",
       "      <td>merrily merrily merrily merrily</td>\n",
       "      <td>adv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>62816244</td>\n",
       "      <td>largest</td>\n",
       "      <td>eng</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>large</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SP</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>328</td>\n",
       "      <td>22756</td>\n",
       "      <td>22755</td>\n",
       "      <td>42518</td>\n",
       "      <td>17177704</td>\n",
       "      <td>18</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>1</td>\n",
       "      <td>one of the largest snakes is the giant anacond...</td>\n",
       "      <td>adj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>61971711</td>\n",
       "      <td>picture's</td>\n",
       "      <td>eng</td>\n",
       "      <td>17</td>\n",
       "      <td></td>\n",
       "      <td>picture</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>328</td>\n",
       "      <td>22729</td>\n",
       "      <td>22728</td>\n",
       "      <td>42372</td>\n",
       "      <td>16979363</td>\n",
       "      <td>3</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0</td>\n",
       "      <td>okay let's put them all take them out and put ...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>61474947</td>\n",
       "      <td>onto</td>\n",
       "      <td>eng</td>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td>onto</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>328</td>\n",
       "      <td>22721</td>\n",
       "      <td>22720</td>\n",
       "      <td>42286</td>\n",
       "      <td>16859093</td>\n",
       "      <td>111</td>\n",
       "      <td>4.709530</td>\n",
       "      <td>2</td>\n",
       "      <td>it's a whole stack so Rusty's pushing Percy on...</td>\n",
       "      <td>prep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>62551990</td>\n",
       "      <td>dumping</td>\n",
       "      <td>eng</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>dump</td>\n",
       "      <td>dʌmpiŋ</td>\n",
       "      <td>dʌmpɪŋ</td>\n",
       "      <td>PRESP</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>328</td>\n",
       "      <td>22743</td>\n",
       "      <td>22743</td>\n",
       "      <td>42433</td>\n",
       "      <td>17094010</td>\n",
       "      <td>17</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>1</td>\n",
       "      <td>it's dumping some dirt</td>\n",
       "      <td>part</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>62904807</td>\n",
       "      <td>mashed</td>\n",
       "      <td>eng</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>mash</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>PASTP</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>328</td>\n",
       "      <td>22766</td>\n",
       "      <td>22764</td>\n",
       "      <td>42548</td>\n",
       "      <td>17198054</td>\n",
       "      <td>6</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1</td>\n",
       "      <td>wanna do mashed potato</td>\n",
       "      <td>part</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     token_id      gloss language  token_order prefix      stem  \\\n",
       "0    62438075       this      eng            1             this   \n",
       "1    61402650       need      eng            3             need   \n",
       "2    62051390   anything      eng            4         anything   \n",
       "3    61453077    merrily      eng            4            merry   \n",
       "4    61453075    merrily      eng            2            merry   \n",
       "..        ...        ...      ...          ...    ...       ...   \n",
       "995  62816244    largest      eng            4            large   \n",
       "996  61971711  picture's      eng           17          picture   \n",
       "997  61474947       onto      eng            9             onto   \n",
       "998  62551990    dumping      eng            2             dump   \n",
       "999  62904807     mashed      eng            3             mash   \n",
       "\n",
       "    actual_phonology model_phonology   suffix  num_morphemes  ... corpus_id  \\\n",
       "0                                                          1  ...       328   \n",
       "1                                                          1  ...       328   \n",
       "2                                                          1  ...       328   \n",
       "3                                     dadj LY              3  ...       328   \n",
       "4                                     dadj LY              3  ...       328   \n",
       "..               ...             ...      ...            ...  ...       ...   \n",
       "995                                        SP              2  ...       328   \n",
       "996                                                        2  ...       328   \n",
       "997                                                        1  ...       328   \n",
       "998           dʌmpiŋ          dʌmpɪŋ    PRESP              2  ...       328   \n",
       "999                                     PASTP              2  ...       328   \n",
       "\n",
       "    speaker_id target_child_id transcript_id utterance_id frequency  \\\n",
       "0        22744           22743         42448     17084600     10570   \n",
       "1        22707           22704         42252     16839687      2591   \n",
       "2        22729           22728         42378     16986849       407   \n",
       "3        22721           22720         42274     16851507        19   \n",
       "4        22721           22720         42274     16851507        19   \n",
       "..         ...             ...           ...          ...       ...   \n",
       "995      22756           22755         42518     17177704        18   \n",
       "996      22729           22728         42372     16979363         3   \n",
       "997      22721           22720         42286     16859093       111   \n",
       "998      22743           22743         42433     17094010        17   \n",
       "999      22766           22764         42548     17198054         6   \n",
       "\n",
       "    log_frequency log_frequency_bin  \\\n",
       "0        9.265775                 4   \n",
       "1        7.859799                 4   \n",
       "2        6.008813                 2   \n",
       "3        2.944439                 1   \n",
       "4        2.944439                 1   \n",
       "..            ...               ...   \n",
       "995      2.890372                 1   \n",
       "996      1.098612                 0   \n",
       "997      4.709530                 2   \n",
       "998      2.833213                 1   \n",
       "999      1.791759                 1   \n",
       "\n",
       "                                       utterance_gloss part_of_speech  \n",
       "0                  this one looks like she's driving a        pro:dem  \n",
       "1                                           now I need              v  \n",
       "2          did we see anything else when we were there      pro:indef  \n",
       "3                      merrily merrily merrily merrily            adv  \n",
       "4                      merrily merrily merrily merrily            adv  \n",
       "..                                                 ...            ...  \n",
       "995  one of the largest snakes is the giant anacond...            adj  \n",
       "996  okay let's put them all take them out and put ...              n  \n",
       "997  it's a whole stack so Rusty's pushing Percy on...           prep  \n",
       "998                             it's dumping some dirt           part  \n",
       "999                             wanna do mashed potato           part  \n",
       "\n",
       "[1000 rows x 32 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterance_glosses = utterances.filter(['id', 'gloss'], axis=1)\n",
    "samples_with_context = thousand_samples.merge(utterance_glosses, how='inner', left_on='utterance_id', right_on='id', suffixes=(None, '_utterance'))\n",
    "samples_with_context.drop(samples_with_context.columns[samples_with_context.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
    "samples_with_context = samples_with_context.rename(columns={'gloss_utterance': 'utterance_gloss', 'id': 'token_id'})\n",
    "samples_with_context = samples_with_context.drop(columns=['id_utterance', 'part_of_speech'])\n",
    "samples_with_context = samples_with_context.merge(all_tokens[['id', 'part_of_speech']], how=\"left\", left_on='token_id', right_on='id')\n",
    "samples_with_context = samples_with_context.drop(columns=['id'])\n",
    "samples_with_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_with_context.to_csv(FULL_SAMPLED_TOKENS_CSV_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "childes_py3",
   "language": "python",
   "name": "childes_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
